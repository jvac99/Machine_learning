{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_esuPRBowY8"
   },
   "source": [
    "# Lista de Exercícios 06\n",
    "\n",
    "### João Victor Aquino Correia (470914)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja_zAtSIDP1B"
   },
   "source": [
    "#### Preparando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7-wpRNVpnET"
   },
   "source": [
    "**Importação das bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G-5_tv9fp0gK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "64A0LU9ap9ZX"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use o seguinte conjunto de dados para as questões a seguir:\n",
    "\n",
    " * Detecção de câncer de mama - Conjunto de dados disponível em: https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWJV9lUcCX1F"
   },
   "source": [
    "**Carregando e definindo as colunas do dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4lL_nHNTCeNy"
   },
   "outputs": [],
   "source": [
    "# Lendo o dataset\n",
    "data = pd.read_csv('breast_cancer_wisconsin_dataset.csv')\n",
    "\n",
    "# retirando a coluna Unnamed: 32 dos conjuntos\n",
    "data.drop(['Unnamed: 32'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEKcASh4GD7H"
   },
   "source": [
    "#### Trabalhando com os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY-_loBiJBya"
   },
   "source": [
    "**Criação do dataset de validação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "# Labels\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divida o conjunto de dados entre Treino (80%) e Teste (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo em conjunto de train e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9GJe3onKW_9"
   },
   "source": [
    "#### Criação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nDz6KhAKBWM"
   },
   "source": [
    "**Classificadores utilizados:**\n",
    "\n",
    "\n",
    "* DecisionTreeClassifier\n",
    "\n",
    "* SVC\n",
    "\n",
    "* KNN\n",
    "\n",
    "* Logistic Regression\n",
    "\n",
    "* Naive Bayes\n",
    "\n",
    "* SGDClassifier\n",
    "\n",
    "* RandomForest\n",
    "\n",
    "* GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A2EPAQJlJ97v"
   },
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "E3KFGl5JKvwe"
   },
   "outputs": [],
   "source": [
    "models['DT'] = tree.DecisionTreeClassifier()\n",
    "models['SVM'] = svm.SVC()\n",
    "models['KNN'] = neighbors.KNeighborsClassifier()\n",
    "models['LogReg'] = linear_model.LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
    "models['NB'] = naive_bayes.GaussianNB()\n",
    "models['SGD'] = linear_model.SGDClassifier()\n",
    "models['RF'] = ensemble.RandomForestClassifier()\n",
    "models['GB'] = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDAÇÃO CRUZADA K-FOLD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique uma validação cruzada 5-Fold (ou seja: k-Fold, com k=5) usando diferentes algoritmos de classificação e escolha o algoritmo que obtiver melhor acurácia. Dica: usar cross_val_score do scikit-learn. Para entender melhor o 5-Fold Cross Validation, veja a figura a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = {}\n",
    "accuracy_scores = {}\n",
    "tree_rmse_scores = {}\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[using-cross-validation-to-evaluate-different-models-regression](https://medium.com/analytics-vidhya/using-cross-validation-to-evaluate-different-models-regression-5f61ec89531)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for models_str in models.keys():\n",
    "    model = models[models_str]\n",
    "    dict_scores[models_str] = cross_val_score(model, X, y, cv=k, scoring='accuracy')\n",
    "    scores = dict_scores[models_str] \n",
    "    accuracy_scores[models_str] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n"
     ]
    }
   ],
   "source": [
    "best_model_key = max(accuracy_scores, key = accuracy_scores.get)\n",
    "print(best_model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Gere (treine) um modelo de classificação usando o melhor algoritmo obtido na questão 2 sobre todo o conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[best_model_key]\n",
    "# Treinando o model\n",
    "model.fit(X_train, y_train)\n",
    "result = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calcule a acurácia do modelo gerado na questão 3 sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.9736842105263158\n",
      "Accuracy score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Avaliando o modelo\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "accuracy_score_result = accuracy_score(y_test, result)\n",
    "print(\"Train score: {}\".format(train_score))\n",
    "print(\"Test score: {}\".format(test_score)) \n",
    "print(\"Accuracy score: {}\".format(test_score)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ESCALONAMENTO DE FEATURES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Reexecute as questões de 1 a 4 só que usando os seguintes escalonamentos de características (features): MinMaxScaler e StandardScaler. Dica: use cada um separadamente para obter uma acurácia final para cada um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PIPELINE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[como-usar-pipelines-no-scikit-learn](https://medium.com/data-hackers/como-usar-pipelines-no-scikit-learn-1398a4cc6ae9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Refaça a questão 5, só que usando Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divida o conjunto de dados entre Treino (80%) e Teste (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo usando pipeline\n",
    "def create_model_pipeline(model):\n",
    "    return Pipeline(steps=[\n",
    "        ('one-hot encoder', OneHotEncoder()),\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('tree', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique uma validação cruzada 5-Fold (ou seja: k-Fold, com k=5) usando diferentes algoritmos de classificação e escolha o algoritmo que obtiver melhor acurácia. Dica: usar cross_val_score do scikit-learn. Para entender melhor o 5-Fold Cross Validation, veja a figura a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_str in models.keys():\n",
    "    model = create_model_pipeline(models[model_str])\n",
    "    # item 2\n",
    "    dict_scores[models_str] = cross_val_score(model, X, y, cv=k, scoring='accuracy')\n",
    "    scores = dict_scores[models_str] \n",
    "    accuracy_scores[models_str] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n"
     ]
    }
   ],
   "source": [
    "best_model_key = max(accuracy_scores, key = accuracy_scores.get)\n",
    "print(best_model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Gere (treine) um modelo de classificação usando o melhor algoritmo obtido na questão 2 sobre todo o conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[best_model_key]\n",
    "# Treinando o model\n",
    "model.fit(X_train, y_train)\n",
    "result = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calcule a acurácia do modelo gerado na questão 3 sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.9649122807017544\n",
      "Accuracy score: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Avaliando o modelo\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "accuracy_score_result = accuracy_score(y_test, result)\n",
    "print(\"Train score: {}\".format(train_score))\n",
    "print(\"Test score: {}\".format(test_score)) \n",
    "print(\"Accuracy score: {}\".format(test_score)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.9649122807017544\n",
      "Average accuracy: 0.957833 (0.015063)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train)\n",
    "train_score = model.score(X_train, y_train)\n",
    "\n",
    "# Avaliando o modelo\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Train score: {}\".format(train_score))\n",
    "print(\"Test score: {}\".format(test_score)) \n",
    "\n",
    "# validando o modelo usando 5-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_validate(model, X=X, y=y, cv=kfold)\n",
    "print(\"Average accuracy: %f (%f)\" %(results['test_score'].mean(), results['test_score'].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRID SEARCH COM VALIDAÇÃO CRUZADA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use um Grid Search com Validação Cruzada 5-Fold sobre o conjunto de treino e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) obtenha os melhores hiper-parâmetros do Gradient Boosting para os seguintes hiper-parâmetros:\n",
    "\n",
    "learning_rate: 0.1, 0.05, 0.01, 0.005, 0.001\n",
    "n_estimators: 10, 50, 100, 200, 400\n",
    "max_depth: 3, 5, 7, 9\n",
    "subsample: 0.5, 0.8, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Gere (treine) um modelo de classificação usando os melhores hiper-parâmetros obtidos no item (a) sobre todo o conjunto de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Calcule a acurácia do modelo gerado no item (b) sobre o conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOMIZED SEARCH COM VALIDAÇÃO CRUZADA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Refaça a Questão 7, só que usando o Randomized Search com Validação Cruzada ao invés do Grid Search com Validação Cruzada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ja_zAtSIDP1B",
    "QEKcASh4GD7H"
   ],
   "name": "lista_de_exercícios03_breast_cancer_wisconsin_dataset.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "156f6b3893f56509e3b4c48ef409c1d1b16c90700e891ae040c162ffb500e427"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
